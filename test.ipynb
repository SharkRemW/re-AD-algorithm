{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shark/miniforge3/envs/gad_test_c/lib/python3.12/site-packages/pygod/utils/utility.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(file_path)\n",
      "/home/shark/miniforge3/envs/gad_test_c/lib/python3.12/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  tensor([1740.8672,  917.8134,  341.4017,  ..., 1194.1462,  622.9437,\n",
      "        2881.2761])\n",
      "predict score:  tensor([1489.1364,  813.9673,  298.5081,  ..., 1055.1726,  553.7695,\n",
      "        2564.6584])\n"
     ]
    }
   ],
   "source": [
    "# train a dominant detector\n",
    "from pygod.detector import DOMINANT\n",
    "\n",
    "from pygod.utils import load_data\n",
    "\n",
    "data = load_data('weibo') # in PyG format\n",
    "model = DOMINANT(num_layers=4, epoch=20)  # hyperparameters can be set here\n",
    "model.fit(data)  # input data is a PyG data object\n",
    "\n",
    "# get outlier scores on the training data (transductive setting)\n",
    "score = model.decision_score_\n",
    "print(\"training score: \", score)\n",
    "# predict labels and scores on the testing data (inductive setting)\n",
    "pred, score = model.predict(data, return_score=True)\n",
    "\n",
    "print(\"predict score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shark/miniforge3/envs/gad_test_c/lib/python3.12/site-packages/pygod/utils/utility.py:173: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(file_path)\n",
      "/home/shark/miniforge3/envs/gad_test_c/lib/python3.12/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  tensor([168.8004,  77.7198,  59.4289,  ..., 100.1070, 103.9973, 351.9234])\n",
      "Predict score:  tensor([167.3499,  77.0197,  59.2666,  ...,  99.1355, 103.0802, 347.6328])\n",
      "AUC Score: 0.8801\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from pygod.detector import CONAD\n",
    "from pygod.utils import load_data\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Load data in PyG format\n",
    "data = load_data('weibo')\n",
    "\n",
    "# Initialize and train the DOMINANT model\n",
    "model = CONAD()  # Hyperparameters can be set here\n",
    "model.fit(data)  # Input data is a PyG data object\n",
    "\n",
    "# Get outlier scores on the training data (transductive setting)\n",
    "train_score = model.decision_score_\n",
    "print(\"Training score: \", train_score)\n",
    "\n",
    "# Predict labels and scores on the testing data (inductive setting)\n",
    "pred, test_score = model.predict(data, return_score=True)\n",
    "print(\"Predict score: \", test_score)\n",
    "\n",
    "# Extract ground truth labels from the data object\n",
    "y_true = data.y.numpy()  # Ground truth labels (1 for anomalies, 0 for normal)\n",
    "\n",
    "# Compute AUC using sklearn's roc_auc_score\n",
    "auc_score = roc_auc_score(y_true, test_score)\n",
    "print(f\"AUC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 2., 2., 2.],\n",
       "         [2., 3., 2., 2.],\n",
       "         [2., 2., 3., 2.],\n",
       "         [2., 2., 2., 3.]]),\n",
       " tensor([0.3333, 0.3333, 0.3333, 0.3333]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.eye(4) + 2\n",
    "x, x.sum(1).pow(-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 0, 1, 2],\n",
      "        [1, 2, 0, 0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import add_self_loops, add_remaining_self_loops\n",
    "import torch\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 2, 1], [1, 2, 0, 1]], dtype=torch.long)\n",
    "edge_index, _ = add_remaining_self_loops(edge_index, num_nodes=3)\n",
    "\n",
    "print(edge_index)\n",
    "# 输出:\n",
    "# tensor([[0, 1, 2, 0, 1, 2],\n",
    "#         [1, 2, 0, 0, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = Parameter(torch.empty(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "        # Step 6: Apply a final bias vector.\n",
    "        out = out + self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm, x_i):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        print(\"x_i: \", x_i.shape)\n",
    "        print(\"x_j: \", x_j.shape)\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_i:  torch.Size([8, 16])\n",
      "x_j:  torch.Size([8, 16])\n",
      "输入节点特征形状: torch.Size([4, 8])\n",
      "输出节点特征形状: torch.Size([4, 16])\n",
      "输出节点特征:\n",
      "tensor([[-0.1596,  0.3181, -0.1366,  0.1896,  0.4349, -0.0353, -0.2308, -0.2075,\n",
      "         -0.1839, -0.4057,  0.0528,  0.1265,  0.3195, -0.2710,  0.2117, -0.4142],\n",
      "        [-0.2343,  0.2402,  0.0196,  0.1361,  0.2385,  0.0307, -0.1567, -0.1859,\n",
      "         -0.1602, -0.4438,  0.0430, -0.0325,  0.2829, -0.2290,  0.0760, -0.2730],\n",
      "        [-0.3008,  0.1754, -0.1129,  0.1463,  0.3277,  0.1270, -0.2049, -0.2250,\n",
      "         -0.2286, -0.4420,  0.0071, -0.1554,  0.1823, -0.2443,  0.3046, -0.3444],\n",
      "        [-0.2260,  0.2534, -0.2691,  0.1997,  0.5242,  0.0611, -0.2791, -0.2466,\n",
      "         -0.2523, -0.4039,  0.0169,  0.0037,  0.2189, -0.2863,  0.4403, -0.4856]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建一个随机图\n",
    "# 假设我们有一个包含 4 个节点的图，每个节点有 16 维特征\n",
    "num_nodes = 5\n",
    "num_features = 8\n",
    "\n",
    "# 节点特征矩阵 x: [num_nodes, num_features]\n",
    "x = torch.rand((num_nodes, num_features))  # 随机生成节点特征\n",
    "\n",
    "# 边索引 edge_index: [2, num_edges]\n",
    "# 这里我们手动定义一些边 (0-1, 1-2, 2-3, 3-0)\n",
    "edge_index = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 0]], dtype=torch.long)\n",
    "\n",
    "# 2. 定义 GCNConv 层\n",
    "in_channels = num_features  # 输入特征维度\n",
    "out_channels = 16           # 输出特征维度\n",
    "conv = GCNConv(in_channels, out_channels)\n",
    "\n",
    "# 3. 前向传播\n",
    "output = conv(x, edge_index)\n",
    "\n",
    "# 打印结果\n",
    "print(\"输入节点特征形状:\", x.shape)\n",
    "print(\"输出节点特征形状:\", output.shape)\n",
    "print(\"输出节点特征:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gad_test_c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
